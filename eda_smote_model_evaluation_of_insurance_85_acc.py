# -*- coding: utf-8 -*-
"""eda-smote-model-evaluation-of-insurance-85-acc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wQk4CVyzX9vBUMpU12zzDoPeQrWaZ_j-

<h1 style="background-color:blue;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;">Vehicle Insurance Model Training and Evaluation</h1>
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
from google.colab.patches import cv2_imshow
import cv2
import matplotlib.pyplot as plt
Image=cv2.imread('/content/drive/MyDrive/frontpage.JPG')
cv2_imshow(Image)

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:450%;text-align:center;border-radius: 15px 50px;">Content</h1>

1. [OverView of Data](#0)
1. [Importing modules and Loading datasets](#1)
1. [Univariate Analysis](#2)
   1. [Gender](#3)
   1. [Vehicle Age](#4)
   1. [Vehicle Damage](#5)
   1. [Age](#6)
       1. [Scaling down Age](#7)
       1. [correlation](#8)
   1. [Annual Premium](#9)
       1. [Scaling down Annual premium](#10)
       1. [correlation](#11)
1. [Multivariate Analysis](#24)
1. [Using SMOTE to solve the problem of imbalanced data](#12)
1. [Spliting data](#13)
1. [Model selection and evaluation](#14)
    1. [DecisionTreeClassifier](#15)
    1. [ RandomForestRegressor](#16)
    1. [LogisticRegression](#17)
    1. [KNN Classifier](#18)
    1. [XGBClassifier](#19)
    1. [GradientBoostingClassifier](#20)
    1. [ CategoricalNB](#21)
    1. [LinearSVC](#22)
1. [Conclusion](#23)

<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Importing modules and Loading datasets</h1>
<a id=1></a>
"""

import pandas as pd
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report,confusion_matrix,r2_score
from sklearn.naive_bayes import CategoricalNB
from sklearn.svm import LinearSVC
import warnings
warnings.filterwarnings('ignore')

data=pd.read_csv('/content/drive/MyDrive/train.csv')
data.head()

data.info()

data.drop(['id'],inplace=True,axis=1)
data.describe()

data.describe(include='O')

data.Response.value_counts()

data.Gender.value_counts()

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Univariate Analysis</h1>
<a id=2></a>

<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">Gender</h1>
<a id=3></a>
"""

plt.figure(figsize=(3,3))
plt.pie(data.Gender.value_counts(),explode=[.1,.2],startangle=90,autopct='%.2f%%',colors=['#FF6103','#7FFF00'],radius=4,labels=['Male','Female'])
plt.title('Gender',fontdict={'fontsize':20,'fontweight':'bold'})
plt.axis('equal')
plt.show()

plt.figure(figsize=(10,8))
sns.countplot(data.Gender,hue=data.Response,palette='Oranges')
plt.show()

data.Gender=pd.Categorical(data.Gender,categories=['Male','Female'],ordered=True).codes
correlation1=data.corr()
correlation1

correlation1[['Gender']].sort_values(by='Gender',ascending=False).style.background_gradient(cmap='Blues')

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">Vehicle  Age</h1>
<a id=4></a>
"""

data.Vehicle_Age.value_counts()

plt.figure(figsize=(3,3))
plt.pie(data.Vehicle_Age.value_counts(),explode=[.1,.1,.1],startangle=90,autopct='%.2f%%',radius=4,colors=['#FF6103','#7FFF00',	'#DC143C'],labels=['1-2 years','< 1 year','> 2 years'])
plt.title('Vehical Age',fontdict={'fontsize':22,'fontweight':'bold'})
plt.axis('equal')
plt.show()

plt.figure(figsize=(10,8))
sns.countplot(data.Vehicle_Age,hue=data.Response,palette='Greens')
plt.show()

data.Vehicle_Age=pd.Categorical(data.Vehicle_Age,categories=['1-2 Year','< 1 Year','> 2 Years'],ordered=True).codes
correlation2=data.corr()
correlation2

correlation2[['Vehicle_Age']].sort_values(['Vehicle_Age'],ascending=False).style.background_gradient(cmap='Greys')

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">Vehicle Damage</h1>
<a id=5></a>
"""

data.Vehicle_Damage.value_counts()

plt.figure(figsize=(3,3))
plt.pie(data.Vehicle_Damage.value_counts(),explode=[.1,.1],startangle=90,autopct='%.2f%%',colors=['#1E90FF','#FFD700',],radius=4,labels=['Yes','No'])
plt.title('Vehicle Damage',fontdict={'fontsize':22,'fontweight':'bold'})
plt.axis('equal')
plt.show()

plt.figure(figsize=(10,8))
sns.countplot(data.Vehicle_Damage,hue=data.Response,palette='Purples')
plt.show()

data.Vehicle_Damage=pd.Categorical(data.Vehicle_Damage,categories=['Yes','No'],ordered=True).codes
correlation3=data.corr()
correlation3

correlation3[['Vehicle_Damage']].sort_values(by='Vehicle_Damage',ascending=False).style.background_gradient(cmap='cool')

"""Here it is quite evident that vehicle damage is highly correlated with, the feature that is that was previously insured

<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">Age</h1>
<a id=6></a>
"""

plt.figure(figsize=(10,8))
sns.distplot(data.Age,color='red',label='Age')
sns.distplot(data.Age[data.Response==1],color='purple')
plt.title('Person bought health insurance Vs Age',fontdict={'fontsize':20,'fontweight':'bold'})
plt.show()

"""Age group of 40-50 have higher chance of buying the health insurance"""

plt.figure(figsize=(10,8))
sns.distplot(data.Age,color='red',label='Age')
sns.distplot(data.Age[data.Response==0],color='blue')
plt.title('Person doesnot bought health insurance Vs Age',fontdict={'fontsize':20,'fontweight':'bold'})
plt.show()

"""
<h1 style="background-color:lightgreen;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;">Scaling Down Age</h1>
<a id=7></a>"""

max_age=max(data.Age)
min_age=min(data.Age)
data.Age=data.Age.apply(lambda x: (x-min_age)/(max_age-min_age))

"""
<h1 style="background-color:lightgreen;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;">correlation</h1>
<a id=8></a>"""

correlation=data.corr()
correlation[['Age']].sort_values(by='Age',ascending=False).style.background_gradient(cmap='Blues')

"""
<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">Annual premium</h1>
<a id=9></a>"""

plt.figure(figsize=(10,8))
sns.distplot(data.Annual_Premium,color='red',label='Annual Premium')
sns.distplot(data.Annual_Premium[data.Response==1],color='blue')
plt.title('Person bought health insurance Vs Annual premium',fontdict={'fontsize':20,'fontweight':'bold'})
plt.show()

plt.figure(figsize=(10,8))
sns.distplot(data.Annual_Premium,color='red',label='Annual Premium')
sns.distplot(data.Annual_Premium[data.Response==0],color='green')
plt.title('Person doesnot bought health insurance Vs Annual premium',fontdict={'fontsize':20,'fontweight':'bold'})
plt.show()

"""
<h1 style="background-color:lightgreen;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;">Scaling Down Annual premium</h1>
<a id=10></a>"""

max_premium=max(data.Annual_Premium)
min_premium=min(data.Annual_Premium)
data.Annual_Premium=data.Annual_Premium.apply(lambda x: (x-min_premium)/(max_premium-min_premium))

"""
<h1 style="background-color:lightgreen;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;">correlation</h1>
<a id=11></a>"""

correlation[['Annual_Premium']].sort_values(by='Annual_Premium',ascending=False).style.background_gradient(cmap='Blues')

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Multivariate Analysis</h1>
<a id=24></a>
"""

plt.figure(figsize=(12,8))
sns.heatmap(correlation,cmap='RdYlGn')
plt.show()

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Using SMOTE to solve the problem of imbalanced data</h1>
<a id=12></a>
"""

oversample=SMOTE()
X,y=oversample.fit_resample(data.iloc[:,:10],data.iloc[:,10])

data

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Spliting train-test Data</h1>
<a id=13></a>
"""

train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=.1,random_state=42)

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Model training And Evaluation</h1>
<a id=14></a>

<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">DecisionTreeClassifier</h1>
<a id=15></a>
"""

from sklearn.tree import DecisionTreeClassifier
model1=DecisionTreeClassifier(random_state=42,max_depth=8)
grid1=GridSearchCV(model1,param_grid={'max_depth':range(5,8)})
grid1.fit(train_x,train_y)

df=pd.DataFrame(grid1.cv_results_)
df

classifier1=DecisionTreeClassifier(random_state=42,max_depth=7)
classifier1.fit(train_x,train_y)

pred_test_y=classifier1.predict(test_x)
pred_train_y=classifier1.predict(train_x)
cm1=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm1,annot=True,cmap='RdYlGn')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">RandomForestClassifier</h1>
<a id=16></a>
"""

classifier2=RandomForestClassifier(random_state=42,max_depth=6)
classifier2.fit(train_x,train_y)

pred_test_y=classifier2.predict(test_x)
pred_train_y=classifier2.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='PiYG')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of train data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">Logistic Regression</h1>
<a id=17></a>
"""

classifier3=LogisticRegression(tol=0.01,max_iter=1000)
classifier3.fit(train_x,train_y)

pred_test_y=classifier3.predict(test_x)
pred_train_y=classifier3.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='Greens')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">KNN Classifier</h1>
<a id=18></a>
"""

classifier4=KNeighborsClassifier(n_neighbors=100)
classifier4.fit(train_x,train_y)

pred_test_y=classifier4.predict(test_x)
pred_train_y=classifier4.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='RdYlGn')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""
<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">XGBoostClassifier</h1>
<a id=19></a>"""

classifier5=XGBClassifier()
classifier5.fit(train_x,train_y)

pred_test_y=classifier5.predict(test_x)
pred_train_y=classifier5.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='YlGn')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">GradientBoosting Classifier</h1>
<a id=20></a>
"""

classifier6=GradientBoostingClassifier(random_state=42)
classifier6.fit(train_x,train_y)

pred_test_y=classifier6.predict(test_x)
pred_train_y=classifier6.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='RdYlGn')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">CategoricalNB</h1>
<a id=21></a>
"""

classifier7=CategoricalNB()
classifier7.fit(train_x,train_y)

pred_test_y=classifier7.predict(test_x)
pred_train_y=classifier7.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='RdBu')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:yellow;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;">LinearSVC</h1>
<a id=22></a>
"""

classifier8=LinearSVC()
classifier8.fit(train_x,train_y)

pred_test_y=classifier8.predict(test_x)
pred_train_y=classifier8.predict(train_x)
cm2=confusion_matrix(test_y,pred_test_y)
plt.figure(figsize=(10,6))
sns.heatmap(cm2,annot=True,cmap='winter')
plt.title('Confusion metrices of test data',fontdict={'fontsize':18,'fontweight':'bold'})
plt.show()

print('Classification report of train data \n',classification_report(train_y,pred_train_y))

print('Classification report of test data \n',classification_report(test_y,pred_test_y))

"""<h1 style="background-color:blue;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;">Conclusion</h1>
<a id=23></a>

<font size='5' color='#008000'>
    From the above analysis it is quite evidient that XGBoostClassifier works better than other algoriths. With test accuracy of about 85%.
    </font>
"""